{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e27c39-e6c4-43c7-a903-9027ef4a1c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"activation\": \"relu\",\n",
      "  \"alpha\": 0.6,\n",
      "  \"batch_size\": 1024,\n",
      "  \"buffer_size\": 200000,\n",
      "  \"buffer_type\": \"uniform\",\n",
      "  \"embed\": false,\n",
      "  \"embed_size\": 0,\n",
      "  \"env\": \"FrozenLake-v1\",\n",
      "  \"env_args\": {\n",
      "    \"is_slippery\": true\n",
      "  },\n",
      "  \"eps_sched_final\": 0.02,\n",
      "  \"eps_sched_len\": 100000,\n",
      "  \"gamma\": 0.995,\n",
      "  \"layer_size\": 64,\n",
      "  \"learning_starts\": 2048,\n",
      "  \"log_step\": 4096,\n",
      "  \"lr\": 0.001,\n",
      "  \"max_episode_steps\": null,\n",
      "  \"num_layers\": 3,\n",
      "  \"save_final\": true,\n",
      "  \"save_max_eps\": false,\n",
      "  \"seed\": 0,\n",
      "  \"steps\": 245760,\n",
      "  \"target_update_freq\": 8192,\n",
      "  \"training_freq\": 64\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "state = torch.load('models/ddqn/frozenlake-v1/reproducibility-0_1alf0ajm_245759_20220131T202108.pth')\n",
    "#state = torch.load('models/ddqn/cartpole-v0/reproducibility-0_1wpkgfkj_327679_20220130T222047.pth')\n",
    "print(json.dumps(state['config'], indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577aa8dd-f4d0-47ae-b5d5-b6adf968b764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQNMLP(\n",
       "  (head): Sequential(\n",
       "    (0): OneHot1d()\n",
       "    (1): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Linear(in_features=64, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "from spin_class.algos.ddqn import make_model\n",
    "\n",
    "kwargs = state['config']['env_args'] if 'env_args' in state['config'] else {}\n",
    "env = gym.make(state['config']['env'], **kwargs)\n",
    "device = torch.device('cpu')\n",
    "q_net = make_model(env, device, state['config'])\n",
    "q_net.load_state_dict(state['q_state_dict'])\n",
    "q_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd271f33-15e3-4a16-8fed-72b5482e4a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "from pyvirtualdisplay import Display\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "# start virtual display\n",
    "if 'display' not in globals():\n",
    "    display = Display(visible=False, size=(1400, 900))\n",
    "    display.start()\n",
    "\n",
    "def play(q_net, env, steps=1000):\n",
    "    env = wrappers.Monitor(env, \"./video\", force=True)\n",
    "    obs_dtype = (\n",
    "        torch.int64\n",
    "        if isinstance(env.observation_space, gym.spaces.Discrete)\n",
    "        else torch.float32\n",
    "    )\n",
    "    obs = env.reset()\n",
    "    for _ in range(steps):\n",
    "        with torch.no_grad():\n",
    "            obs_t = torch.as_tensor(obs, dtype=obs_dtype, device=device).unsqueeze(\n",
    "                    0\n",
    "                )\n",
    "            q = q_net(obs_t)[0]\n",
    "            action = torch.argmax(q).cpu().numpy().tolist()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(_)\n",
    "            break\n",
    "    env.close()\n",
    "\n",
    "    video = io.open('./video/openaigym.video.%s.video000000.mp4' % env.file_infix, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    ipythondisplay.display(HTML(data='''\n",
    "        <video alt=\"test\" autoplay loop controls style=\"height: 400px;\">\n",
    "            <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "        </video>'''.format(encoded.decode('ascii'))))\n",
    "\n",
    "    #HTML(data='''\n",
    "    #    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>\n",
    "    #'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e41138-bed2-4dc9-a3b6-d545558c1518",
   "metadata": {},
   "outputs": [],
   "source": [
    "play(q_net, env, steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0935bdf6-d61c-4b81-8c04-73a4dbbcfcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "def play_frozenlake(q_net, env, eps=0.0):\n",
    "    obs_dtype = (\n",
    "        torch.int64\n",
    "        if isinstance(env.observation_space, gym.spaces.Discrete)\n",
    "        else torch.float32\n",
    "    )\n",
    "    obs = env.reset()\n",
    "    print('====== step 0 ======')\n",
    "    env.render()\n",
    "    for i in range(100):\n",
    "        with torch.no_grad():\n",
    "            obs_t = torch.as_tensor(obs, dtype=obs_dtype, device=device).unsqueeze(0)\n",
    "            q = q_net(obs_t)[0]\n",
    "            action = torch.argmax(q).cpu().numpy().tolist() if random.random() > eps else env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        print(f'====== step {i + 1} ======')\n",
    "        env.render()\n",
    "        if done:\n",
    "            print(_)\n",
    "            break\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a6e6dcc-ad2b-47b5-8613-6ab3e031b8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== step 0 ======\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "====== step 1 ======\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "====== step 2 ======\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "====== step 3 ======\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "====== step 4 ======\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "====== step 5 ======\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "====== step 6 ======\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "====== step 7 ======\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "====== step 8 ======\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "====== step 9 ======\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "====== step 10 ======\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "====== step 11 ======\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "====== step 12 ======\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "====== step 13 ======\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "====== step 14 ======\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "====== step 15 ======\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "DQNMLP(\n",
      "  (head): Sequential(\n",
      "    (0): OneHot1d()\n",
      "    (1): Linear(in_features=16, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (6): ReLU()\n",
      "    (7): Linear(in_features=64, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "play_frozenlake(q_net, env, 0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
