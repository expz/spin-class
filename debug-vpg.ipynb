{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896ea7a4-1f76-4fcb-bfbe-dc4345c8eb38",
   "metadata": {},
   "source": [
    "# Debug VPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21e19d43-640b-4f2b-a6d7-58b3f3b07ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import gym\n",
    "import gym.spaces\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.distributions.normal import Normal\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "import wandb\n",
    "\n",
    "\n",
    "def shape(space: gym.Space):\n",
    "    if isinstance(space, gym.spaces.Discrete):\n",
    "        return tuple()\n",
    "    elif isinstance(space, gym.spaces.Box):\n",
    "        return space.sample().shape\n",
    "    else:\n",
    "        raise Exception(f\"Unsupported space type: {type(space)}\")\n",
    "\n",
    "\n",
    "class ScaleLayer1d(nn.Module):\n",
    "    def __init__(self, scale: torch.Tensor):\n",
    "        super(ScaleLayer1d, self).__init__()\n",
    "\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return torch.matmul(x, self.scale)\n",
    "\n",
    "\n",
    "class OneHot1d(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super(OneHot1d, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        y = torch.as_tensor(x, dtype=torch.int64)\n",
    "        return F.one_hot(y, num_classes=self.num_classes).to(torch.float32)\n",
    "\n",
    "\n",
    "class VPGModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        layers: List[Tuple[str, int, str]],\n",
    "        device: torch.DeviceObjType,\n",
    "    ):\n",
    "        super(VPGModel, self).__init__()\n",
    "\n",
    "        self.env = env\n",
    "        self.device = device\n",
    "\n",
    "        if isinstance(env.observation_space, gym.spaces.Box):\n",
    "            self.layers = [(\"input\", shape(env.observation_space)[0])] + layers\n",
    "        elif isinstance(env.observation_space, gym.spaces.Discrete):\n",
    "            self.layers = [\n",
    "                (\"input\", 1),\n",
    "            ] + layers\n",
    "\n",
    "        self.model = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.model(x)\n",
    "\n",
    "    def build_model(self, conf: List[Union[Tuple[str, int], Tuple[str, int, str]]]):\n",
    "        layers = []\n",
    "        t, prev_size = conf[0]\n",
    "        assert t == \"input\"\n",
    "        for layer in conf[1:]:\n",
    "            if layer[0] == \"linear\":\n",
    "                size = layer[1]\n",
    "                layers.append(nn.Linear(prev_size, size))\n",
    "                if layer[2] == \"relu\":\n",
    "                    layers.append(nn.ReLU())\n",
    "                elif layer[2] == \"none\":\n",
    "                    pass\n",
    "                elif layer[2] == \"tanh\":\n",
    "                    layers.append(nn.Tanh())\n",
    "                else:\n",
    "                    raise NotImplementedError(\n",
    "                        f\"Unrecognized activation type: {layer[2]}\"\n",
    "                    )\n",
    "            elif layer[0] == \"scaling\":\n",
    "                assert isinstance(layer[1], torch.Tensor)\n",
    "                layers.append(ScaleLayer1d(layer[1]))\n",
    "            elif layer[0] == \"onehot\":\n",
    "                size = layer[1]\n",
    "                layers.append(OneHot1d(size))\n",
    "            elif layer[0] == \"embed\":\n",
    "                num_classes = layer[1]\n",
    "                size = layer[2]\n",
    "                layers.append(\n",
    "                    nn.Embedding(\n",
    "                        num_classes,\n",
    "                        size,\n",
    "                        sparse=False,\n",
    "                        dtype=torch.float32,\n",
    "                        device=self.device,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Unrecognized layer type: {layer[0]}\")\n",
    "            prev_size = size\n",
    "        return nn.Sequential(*layers).to(self.device)\n",
    "\n",
    "\n",
    "class VPGValueModel(VPGModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        layers: List[Tuple[str, int, str]],\n",
    "        device: torch.DeviceObjType,\n",
    "    ):\n",
    "        super(VPGValueModel, self).__init__(env, layers, device)\n",
    "\n",
    "        self.layers += [(\"linear\", 1, \"none\")]\n",
    "        self.model = self.build_model(self.layers)\n",
    "\n",
    "\n",
    "class VPGPolicyModel(VPGModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        layers: List[Tuple[str, int, str]],\n",
    "        device: torch.DeviceObjType,\n",
    "    ):\n",
    "        super(VPGPolicyModel, self).__init__(env, layers, device)\n",
    "\n",
    "\n",
    "class VPGGaussianPolicyModel(VPGPolicyModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        layers: List[Tuple[str, int, str]],\n",
    "        std_logits: float,\n",
    "        device: torch.torch.DeviceObjType,\n",
    "    ):\n",
    "        super(VPGGaussianPolicyModel, self).__init__(env, layers, device)\n",
    "\n",
    "        assert isinstance(env.action_space, gym.spaces.Box)\n",
    "\n",
    "        signal_count = env.action_space.shape[0]\n",
    "\n",
    "        output_layers = [(\"linear\", signal_count, \"tanh\")]\n",
    "\n",
    "        # TOOD: Support infinite sized boxes.\n",
    "        signal_scale = torch.as_tensor(\n",
    "            (env.action_space.high - env.action_space.low) / 2.0,\n",
    "            dtype=torch.float32,\n",
    "            device=device,\n",
    "        )\n",
    "        if not torch.all(torch.isclose(signal_scale, torch.ones_like(signal_scale))):\n",
    "            output_layers.append((\"scaling\", signal_scale))\n",
    "\n",
    "        if not np.all(\n",
    "            np.isclose(env.action_space.high, -env.action_space.low, equal_nan=True)\n",
    "        ):\n",
    "            # TODO: add offset layer.\n",
    "            raise NotImplementedError(\n",
    "                \"Box ranges which are not centered at 0 are not yet implemented.\"\n",
    "            )\n",
    "\n",
    "        self.layers += output_layers\n",
    "        self.model = self.build_model(self.layers)\n",
    "\n",
    "        self.std = torch.exp(\n",
    "            std_logits * torch.ones((signal_count,), dtype=torch.float32, device=device)\n",
    "        )\n",
    "\n",
    "    def distribution(self, output: torch.Tensor):\n",
    "        return Normal(output, self.std)\n",
    "\n",
    "\n",
    "class VPGCategoricalPolicyModel(VPGPolicyModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        layers: List[Tuple[str, int, str]],\n",
    "        device: torch.torch.DeviceObjType,\n",
    "    ):\n",
    "        super(VPGCategoricalPolicyModel, self).__init__(env, layers, device)\n",
    "\n",
    "        assert isinstance(env.action_space, gym.spaces.Discrete)\n",
    "\n",
    "        output_layers = [(\"linear\", env.action_space.n, \"none\")]\n",
    "        self.layers += output_layers\n",
    "        self.model = self.build_model(self.layers)\n",
    "\n",
    "    def distribution(self, output: torch.Tensor):\n",
    "        return Categorical(logits=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b155bc67-9dc1-413d-aee8-ea9e643ce55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    \"cartpole\": {\n",
    "        \"env\": \"CartPole-v0\",\n",
    "        \"save_max_eps\": False,\n",
    "        \"vf_layers\": [\n",
    "            (\"linear\", 16, \"relu\"),\n",
    "            (\"linear\", 16, \"relu\"),\n",
    "            (\"linear\", 16, \"relu\"),\n",
    "            (\"linear\", 16, \"relu\"),\n",
    "        ],\n",
    "        \"pi_layers\": [\n",
    "            (\"linear\", 128, \"relu\"),\n",
    "            (\"linear\", 128, \"relu\"),\n",
    "            (\"linear\", 128, \"relu\"),\n",
    "        ],\n",
    "        \"pi_lr\": 0.003,\n",
    "        \"vf_lr\": 0.0015,\n",
    "        \"vf_train_iters\": 80,\n",
    "        \"gamma\": 0.995,\n",
    "        \"lambda\": 0.95,\n",
    "        \"batch_size\": 1024,\n",
    "        \"steps\": 163840,\n",
    "        \"log_step\": 8192,\n",
    "        \"seed\": 42,\n",
    "    },\n",
    "    \"invertedpendulum\": {\n",
    "        \"env\": \"InvertedPendulum-v2\",\n",
    "        \"save_max_eps\": False,\n",
    "        \"vf_layers\": [\n",
    "            (\"linear\", 128, \"relu\"),\n",
    "            (\"linear\", 128, \"relu\"),\n",
    "        ],\n",
    "        \"pi_layers\": [\n",
    "            (\"linear\", 64, \"relu\"),\n",
    "            (\"linear\", 64, \"relu\"),\n",
    "            (\"linear\", 64, \"relu\"),\n",
    "        ],\n",
    "        \"pi_lr\": 0.004,\n",
    "        \"vf_lr\": 0.1,\n",
    "        \"vf_train_iters\": 320,\n",
    "        \"std_logits\": -0.5,\n",
    "        \"gamma\": 0.995,\n",
    "        \"lambda\": 0.99,\n",
    "        \"batch_size\": 1024,\n",
    "        \"steps\": 163840,\n",
    "        \"log_step\": 8192,\n",
    "        \"seed\": 42,\n",
    "    },\n",
    "    \"frozenlake\": {\n",
    "        \"env\": \"FrozenLake-v1\",\n",
    "        \"env_args\": {\n",
    "            \"is_slippery\": False,\n",
    "        },\n",
    "        \"save_max_eps\": False,\n",
    "        \"vf_layers\": [\n",
    "            (\"embed\", 16, 8),\n",
    "            (\"linear\", 128, \"relu\"),\n",
    "            (\"linear\", 128, \"relu\"),\n",
    "            (\"linear\", 128, \"relu\"),\n",
    "            (\"linear\", 128, \"relu\"),\n",
    "        ],\n",
    "        \"pi_layers\": [\n",
    "            (\"embed\", 16, 8),\n",
    "            (\"linear\", 256, \"relu\"),\n",
    "            (\"linear\", 256, \"relu\"),\n",
    "            (\"linear\", 256, \"relu\"),\n",
    "        ],\n",
    "        \"pi_lr\": 0.01,\n",
    "        \"vf_lr\": 0.004,\n",
    "        \"vf_train_iters\": 80,\n",
    "        \"gamma\": 0.99,\n",
    "        \"lambda\": 0.97,\n",
    "        \"batch_size\": 4096,\n",
    "        \"steps\": 163840,\n",
    "        \"log_step\": 8192,\n",
    "        \"seed\": 42,\n",
    "    },\n",
    "    \"halfcheetah\": {\n",
    "        \"env\": \"HalfCheetah-v2\",\n",
    "        \"save_max_eps\": False,\n",
    "        \"vf_layers\": [\n",
    "            (\"linear\", 128, \"relu\"),\n",
    "            (\"linear\", 128, \"relu\"),\n",
    "        ],\n",
    "        \"pi_layers\": [\n",
    "            (\"linear\", 64, \"relu\"),\n",
    "            (\"linear\", 64, \"relu\"),\n",
    "            (\"linear\", 64, \"relu\"),\n",
    "        ],\n",
    "        \"pi_lr\": 0.004,\n",
    "        \"vf_lr\": 0.1,\n",
    "        \"vf_train_iters\": 320,\n",
    "        \"std_logits\": -0.5,\n",
    "        \"gamma\": 0.995,\n",
    "        \"lambda\": 0.99,\n",
    "        \"batch_size\": 1024,\n",
    "        \"steps\": 163840,\n",
    "        \"log_step\": 8192,\n",
    "        \"seed\": 42,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39da80cc-70d8-491c-9aa6-eddf775fc493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 1\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import gym\n",
    "import random\n",
    "import spin_class.algos.vpg as vpg\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from typing import Any, Dict\n",
    "\n",
    "import spin_class.utils as utils\n",
    "# import spin_class.config as conf\n",
    "\n",
    "\n",
    "env_name = 'frozenlake'\n",
    "\n",
    "i = random.randrange(torch.cuda.device_count())\n",
    "device = torch.device(f\"cuda:{i}\")\n",
    "print(\"Using GPU\", i)\n",
    "\n",
    "config = conf[env_name]\n",
    "\n",
    "kwargs = config[\"env_args\"] if \"env_args\" in config else {}\n",
    "env = gym.make(config[\"env\"], **kwargs)\n",
    "\n",
    "config[\"seed\"] = 0\n",
    "\n",
    "# run = wandb.init(\n",
    "#     project=f\"vpg-{args.env}\",\n",
    "#     config=config,\n",
    "#     name=f\"reproducibility-{seed}\",\n",
    "# )\n",
    "\n",
    "run_id = ''\n",
    "run_name = 'debug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "656106ae-62f2-4320-82eb-937f72a05ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 4096, avg total rew: 0.0203, avg eps length: 7.54, min eps length: 2, pi loss: 0.002584, vf_loss: 0.021279\n",
      "steps: 8192, avg total rew: 0.0000, avg eps length: 6.67, min eps length: 2, pi loss: 0.041287, vf_loss: 0.000000\n",
      "steps: 12288, avg total rew: 0.0070, avg eps length: 7.10, min eps length: 2, pi loss: 0.088946, vf_loss: 0.014411\n",
      "steps: 16384, avg total rew: 0.0028, avg eps length: 11.44, min eps length: 2, pi loss: 0.015576, vf_loss: 0.001599\n",
      "steps: 20480, avg total rew: 0.0699, avg eps length: 10.98, min eps length: 2, pi loss: -0.024131, vf_loss: 0.069208\n",
      "steps: 24576, avg total rew: 0.3925, avg eps length: 8.98, min eps length: 2, pi loss: -0.074563, vf_loss: 0.209422\n",
      "steps: 28672, avg total rew: 0.7974, avg eps length: 7.54, min eps length: 2, pi loss: -0.091247, vf_loss: 0.123361\n",
      "steps: 32768, avg total rew: 0.9799, avg eps length: 6.34, min eps length: 4, pi loss: -0.052225, vf_loss: 0.016370\n",
      "steps: 36864, avg total rew: 1.0000, avg eps length: 6.03, min eps length: 6, pi loss: -0.046408, vf_loss: 0.000225\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m p \u001b[38;5;241m=\u001b[39m pi(obs_t)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     74\u001b[0m v \u001b[38;5;241m=\u001b[39m vf(obs_t)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 75\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[43mpi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m a \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m     77\u001b[0m obs, r, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(a\u001b[38;5;241m.\u001b[39mitem())\n",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36mVPGCategoricalPolicyModel.distribution\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistribution\u001b[39m(\u001b[38;5;28mself\u001b[39m, output: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/devbox/src/spinning-up/venv/lib/python3.8/site-packages/torch/distributions/categorical.py:64\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     63\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize()\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCategorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/devbox/src/spinning-up/venv/lib/python3.8/site-packages/torch/distributions/distribution.py:62\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m             )\n\u001b[0;32m---> 62\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe parameter \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m has invalid values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(param))\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28msuper\u001b[39m(Distribution, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Make the training reproducible.\n",
    "env.seed(config[\"seed\"])\n",
    "random.seed(config[\"seed\"])\n",
    "np.random.seed(config[\"seed\"])\n",
    "torch.random.manual_seed(config[\"seed\"])\n",
    "torch.cuda.manual_seed_all(config[\"seed\"])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "if isinstance(env.action_space, gym.spaces.Box):\n",
    "    pi = VPGGaussianPolicyModel(\n",
    "        env, config[\"pi_layers\"], config[\"std_logits\"], device\n",
    "    )\n",
    "elif isinstance(env.action_space, gym.spaces.Discrete):\n",
    "    pi = VPGCategoricalPolicyModel(env, config[\"pi_layers\"], device)\n",
    "else:\n",
    "    raise NotImplementedError(\n",
    "        f\"Action space type not yet supported: {type(env.action_space)}\"\n",
    "    )\n",
    "vf = VPGValueModel(env, config[\"vf_layers\"], device)\n",
    "\n",
    "# wandb.watch(pi)\n",
    "# wandb.watch(vf)\n",
    "\n",
    "pi_opt = Adam(pi.parameters(), lr=config[\"pi_lr\"])\n",
    "vf_opt = Adam(vf.parameters(), lr=config[\"vf_lr\"])\n",
    "\n",
    "save_max_eps = config[\"save_max_eps\"]\n",
    "gamma = config[\"gamma\"]\n",
    "lam = config[\"lambda\"]\n",
    "batch_size = config[\"batch_size\"]\n",
    "avg_eps_len = 0\n",
    "max_performance = False\n",
    "epsilon = 1e-6\n",
    "obs_dtype = (\n",
    "    torch.int64\n",
    "    if isinstance(env.observation_space, gym.spaces.Discrete)\n",
    "    else torch.float32\n",
    ")\n",
    "\n",
    "\n",
    "model_dir = f\"models/vpg/{env.spec.id.lower()}\"\n",
    "os.makedirs(f\"{model_dir}/pi\", mode=0o755, exist_ok=True)\n",
    "os.makedirs(f\"{model_dir}/vf\", mode=0o755, exist_ok=True)\n",
    "\n",
    "for k in range(0, config[\"steps\"], batch_size):\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    obss = np.zeros([batch_size] + list(shape(env.observation_space)))\n",
    "    if len(obss.shape) == 1:\n",
    "        obss = np.expand_dims(obss, axis=1)\n",
    "    rets = torch.zeros(batch_size, dtype=torch.float32, device=device)\n",
    "    advs = torch.zeros(batch_size, dtype=torch.float32, device=device)\n",
    "    as_ = torch.zeros(batch_size, dtype=torch.float32, device=device)\n",
    "    rs = torch.zeros(batch_size, dtype=torch.float32, device=device)\n",
    "    eps_vs, eps_rs = torch.zeros(\n",
    "        batch_size, dtype=torch.float32, device=device\n",
    "    ), torch.zeros(batch_size, dtype=torch.float32, device=device)\n",
    "    ptr = 0\n",
    "    eps_lens = []\n",
    "    eps_len = 0\n",
    "    total_rews = []\n",
    "    total_rew = 0\n",
    "    for i in range(batch_size):\n",
    "        eps_len += 1\n",
    "\n",
    "        obss[i, :] = obs\n",
    "\n",
    "        with torch.no_grad():\n",
    "            obs_t = torch.as_tensor(\n",
    "                obs, dtype=obs_dtype, device=device\n",
    "            ).unsqueeze(0)\n",
    "            p = pi(obs_t)[0]\n",
    "            v = vf(obs_t)[0]\n",
    "            dist = pi.distribution(p)\n",
    "            a = dist.sample()\n",
    "            obs, r, done, _ = env.step(a.item())\n",
    "\n",
    "        eps_vs[eps_len - 1] = v\n",
    "        as_[i] = a\n",
    "        eps_rs[eps_len - 1] = r\n",
    "        rs[i] = r\n",
    "\n",
    "        total_rew += r\n",
    "\n",
    "        if done or i == batch_size - 1:\n",
    "            if done:\n",
    "                eps_lens.append(eps_len)\n",
    "                total_rews.append(total_rew)\n",
    "            ret = 0\n",
    "            for i in range(eps_len - 1, -1, -1):\n",
    "                ret = eps_rs[i] + gamma * ret\n",
    "                rets[ptr + i] = ret\n",
    "            adv = 0\n",
    "            for i in range(eps_len - 1, 0, -1):\n",
    "                adv = (\n",
    "                    eps_rs[i - 1] + gamma * eps_vs[i] - eps_vs[i - 1]\n",
    "                ) + lam * gamma * adv\n",
    "                advs[ptr + i] = adv\n",
    "            advs[ptr + eps_len - 1] = eps_rs[-1] - eps_vs[-1]\n",
    "            ptr += eps_len\n",
    "            done = False\n",
    "            eps_len = 0\n",
    "            total_rew = 0\n",
    "            obs = env.reset()\n",
    "\n",
    "    step = k + batch_size\n",
    "\n",
    "    avg_total_rew = sum(total_rews) / len(total_rews)\n",
    "    max_total_rew = max(total_rews)\n",
    "    min_total_rew = min(total_rews)\n",
    "    std_total_rew = np.std(total_rews).tolist()\n",
    "    avg_eps_len = sum(eps_lens) / len(eps_lens)\n",
    "    max_eps_len = max(eps_lens)\n",
    "    min_eps_len = min(eps_lens)\n",
    "    std_eps_len = np.std(eps_lens).tolist()\n",
    "\n",
    "    obs_b = torch.as_tensor(obss.squeeze(), dtype=obs_dtype, device=device)\n",
    "    a_b = as_\n",
    "    ret_b = rets\n",
    "\n",
    "    adv_b = advs\n",
    "    std, mean = adv_b.std(dim=0), adv_b.mean()\n",
    "    adv_b = (adv_b - mean) / (std + epsilon)\n",
    "    \n",
    "    pi_opt.zero_grad()\n",
    "\n",
    "    logp_b = pi.distribution(pi(obs_b)).log_prob(a_b)\n",
    "    pi_loss = -(logp_b * adv_b).mean()\n",
    "    pi_loss.backward()\n",
    "    pi_opt.step()\n",
    "\n",
    "    for i in range(config[\"vf_train_iters\"]):\n",
    "        vf_opt.zero_grad()\n",
    "        v_b = vf(obs_b).squeeze()\n",
    "        vf_loss = ((v_b - ret_b) ** 2).mean()\n",
    "        vf_loss.backward()\n",
    "        vf_opt.step()\n",
    "\n",
    "    if step % config[\"log_step\"] == 0:\n",
    "        pass\n",
    "        # wandb.log(\n",
    "        #     {\n",
    "        #         \"avg_total_rew\": avg_total_rew,\n",
    "        #         \"max_total_rew\": max_total_rew,\n",
    "        #         \"min_total_rew\": min_total_rew,\n",
    "        #         \"std_total_rew\": std_total_rew,\n",
    "        #         \"avg_eps_len\": avg_eps_len,\n",
    "        #         \"max_eps_len\": max_eps_len,\n",
    "        #         \"min_eps_len\": min_eps_len,\n",
    "        #         \"std_eps_len\": std_eps_len,\n",
    "        #         \"pi_loss\": pi_loss.item(),\n",
    "        #         \"vf_loss\": vf_loss.item(),\n",
    "        #         \"adv_std\": std,\n",
    "        #         \"adv_mean\": mean,\n",
    "        #         \"steps\": step,\n",
    "        #     }\n",
    "        # )\n",
    "\n",
    "    print(\n",
    "        f\"steps: {step}, avg total rew: {avg_total_rew:.4f}, avg eps length: {avg_eps_len:.2f}, min eps length: {min_eps_len}, pi loss: {pi_loss.item():.6f}, vf_loss: {vf_loss:.6f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7cd4d21-5820-4c67-bb33-5c22e90e351c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.]], device='cuda:1')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = OneHot1d(num_classes=16)\n",
    "l.forward(obs_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4dfcd0b-8e52-48ad-a570-7851efbcfe02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): OneHot1d()\n",
      "  (1): Linear(in_features=16, out_features=128, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (8): ReLU()\n",
      "  (9): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vf.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24cf745c-fda2-4d29-b1e1-3c63f733b56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average return: 0.0149\n"
     ]
    }
   ],
   "source": [
    "num_eps = 10000\n",
    "rets = []\n",
    "for i in range(num_eps):\n",
    "    obs = env.reset()\n",
    "    ret = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        obs, r, done, _ = env.step(env.action_space.sample())\n",
    "        ret += r\n",
    "    rets.append(ret)\n",
    "    \n",
    "print(f'average return: {sum(rets) / len(rets)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c180c99-1c0d-4fe5-9c8a-53160f5d3e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "[-4.136449813842773, 20.60943031311035, 4.27929162979126, -24.616153717041016]\n",
      "tensor([1.7906e-11, 1.0000e+00, 8.0893e-08, 2.2844e-20], device='cuda:1')\n",
      "{'prob': 1.0}\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "[-4.060048580169678, 15.172551155090332, 4.42076301574707, -19.144397735595703]\n",
      "tensor([4.4400e-09, 9.9998e-01, 2.1407e-05, 1.2483e-15], device='cuda:1')\n",
      "{'prob': 1.0}\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "[-1.4209874868392944, -8.478757858276367, 8.982975006103516, -6.1250128746032715]\n",
      "tensor([3.0311e-05, 2.6089e-08, 9.9997e-01, 2.7458e-07], device='cuda:1')\n",
      "{'prob': 1.0}\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "[-1.3930362462997437, -8.16796875, 9.203563690185547, -6.526035308837891]\n",
      "tensor([2.5000e-05, 2.8551e-08, 9.9997e-01, 1.4747e-07], device='cuda:1')\n",
      "{'prob': 1.0}\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "[-5.386871337890625, 26.826488494873047, 4.038366794586182, -30.372730255126953]\n",
      "tensor([1.0231e-14, 1.0000e+00, 1.2684e-10, 1.4411e-25], device='cuda:1')\n",
      "{'prob': 1.0}\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "[-1.873536229133606, -6.069185733795166, 8.012393951416016, -5.608665943145752]\n",
      "tensor([5.0883e-05, 7.6635e-07, 9.9995e-01, 1.2146e-06], device='cuda:1')\n",
      "{'prob': 1.0}\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "obs_dtype = torch.int64 if isinstance(env.observation_space, gym.spaces.Discrete) else torch.float32\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "done = False\n",
    "while not done:\n",
    "    with torch.no_grad():\n",
    "        obs_t = torch.as_tensor(obs, dtype=obs_dtype, device=device).unsqueeze(0)\n",
    "        p = pi(obs_t)[0]\n",
    "        print(p.cpu().numpy().tolist())\n",
    "        dist = pi.distribution(p)\n",
    "        print(dist.probs)\n",
    "        a = dist.sample()\n",
    "        obs, r, done, info = env.step(a.item())\n",
    "        print(info)\n",
    "        env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6d809e3-48e1-4cc1-92c2-619d91caec89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_env_name',\n",
       " '_kwargs',\n",
       " 'entry_point',\n",
       " 'id',\n",
       " 'make',\n",
       " 'max_episode_steps',\n",
       " 'nondeterministic',\n",
       " 'order_enforce',\n",
       " 'reward_threshold']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(env.spec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
